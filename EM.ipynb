{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Algorithm for image segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM Algorithm\n",
    "#### Performance \n",
    "For better performance, the following principles are followed:\n",
    "1. In order to avoid high cpu usage, loops in python are avoided\n",
    "   (especially loops over the size of the dataset).\n",
    "   Numpy opetations (in C) over whole arrays are used instead.\n",
    "2. In order to avoid high memory and cpu usage,\n",
    "   array allocations are avoided and intermediate and final results\n",
    "   are stored in preallocated buffers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spherical_gaussian(data_m_d, mean_c_d, std_c,\n",
    "                       buffer_m_d, buffer_c,\n",
    "                       out_m_c):\n",
    "    k = len(mean_c_d)\n",
    "    # math: buffer_c = 2*std\n",
    "    np.multiply(std_c, 2, out=buffer_c)\n",
    "    for c in xrange(k):\n",
    "        # math: buffer_m_d = -(x-m_c)^2\n",
    "        np.subtract(data_m_d, mean_c_d[c], out=buffer_m_d)\n",
    "        np.square(buffer_m_d, out=buffer_m_d)\n",
    "        np.multiply(buffer_m_d, -1, out=buffer_m_d)\n",
    "        # math: buffer_m_d = exp{ [-(x-m_c)^2] / 2*std }\n",
    "        np.divide(buffer_m_d, buffer_c[c], out=buffer_m_d)\n",
    "        np.exp(buffer_m_d, out=buffer_m_d)\n",
    "        #  math: apply product to exp{ [-(x-m_c)^2] / 2*std }\n",
    "        np.prod(buffer_m_d, axis=1, out=out_m_c.T[c])\n",
    "        \n",
    "    # math: buffer_c = sqrt{2*pi*std}\n",
    "    np.multiply(buffer_c, np.pi, buffer_c)\n",
    "    np.sqrt(buffer_c, out=buffer_c)\n",
    "    # divide all by sqrt{2*pi*std} ^ k\n",
    "    # iterative divisions to avoid +Inf for big k\n",
    "    for c in xrange(k):\n",
    "        np.divide(out_m_c, buffer_c, out=out_m_c)\n",
    "\n",
    "    \n",
    "# Batch sum to avoid very big with very small additions\n",
    "def batch_sum_axis0(arr_m_k, buffer_k, out_k):\n",
    "    m = len(arr_m_k)\n",
    "    out_k.fill(0)\n",
    "    for i in xrange(1 + m // 1000):\n",
    "        start = 1000*i\n",
    "        end = min(1000*(i+1), m)\n",
    "        arr_m_k[start:end, :].sum(axis=0, out=buffer_k)\n",
    "        np.add(out_k, buffer_k, out=out_k)\n",
    "    \n",
    "    \n",
    "def reconstruction_error(current_m_d, initial_m_d, buffer_m_d):\n",
    "    np.subtract(current_m_d, initial_m_d, out=buffer_m_d)\n",
    "    np.square(buffer_m_d, out=buffer_m_d)\n",
    "    return buffer_m_d.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Algorithm Implementation\n",
    "#### Cluster Initialization\n",
    "The **means** of the clusters are initialized as a *linspace* around the total mean of the data.<br>\n",
    "The *bounds of the linspace* are set for each dimension with the following rules:\n",
    "> `Lower bound = mean_d - 0.2*k*std_d` <br>\n",
    "> `Upper bound = mean_d + 0.2*k*std_d` <br>\n",
    ">   where `mean_d`, `std_d` are the mean and std of the dimension (independently)\n",
    "> * if the lower (upper) bound differs from the mean more than 2.5*std it is adjusted to:\n",
    ">   `mean-2.5*std` (`mean+2.5*std`) <br>\n",
    "> * The lower bound cannot be lesser than the total minimum of the dimension <br>\n",
    "> * The upper bound cannot be greater than the total maximum of the dimension\n",
    "\n",
    "The **std** of all clusters is set to 1 <br>\n",
    "The **pi** of all clusters is set to 1/k\n",
    "\n",
    "#### Algorithm termination\n",
    "The algoritmh terminates when one the folowing occurs:\n",
    "* Maximun number of iterations is reached\n",
    "* All convergence criteria are met\n",
    "\n",
    "\n",
    "**Convergence criteria** take into account the difference that was noticed on the \n",
    "cluster means and stds. Specifically:\n",
    "1. The mean absolute diffenrence between the current and previous cluster means\n",
    "   (over all dimensions) is lesser than `d / sqrt(k)` and\n",
    "2. The mean absolute diffenrence between the current and previous cluster sdts\n",
    "   is lesser than `d / sqrt(k)`\n",
    "   \n",
    "#### Numerical stability\n",
    "Measures taken for numerical stability include: \n",
    "* Summation over the gamas is done in batches to avoid additions\n",
    "  between very large and very small values\n",
    "* In the case a datum is away from all cluster means, and thus all gaussian probality \n",
    "  densities are aproximated with zero, the datum is assigned equally over all clusters\n",
    "  (avoiding devision by zero)\n",
    "* Divisions of the form `a/b^k` is performed via `k` successive divisons with `b`\n",
    "  to avoid errors when `k` is big\n",
    "* Minimum values are defined for extreme cases such as when a cluster has zero \n",
    "  density over all the data\n",
    "\n",
    "#### Logging and visualizing intermediate results\n",
    "The EM class (which encapsulates the algorithm) allow for a custom function\n",
    "to be called after cluster initialization and each iteration. This enables the\n",
    "ability logging and visualizing intermediate stages of the algorithm application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_con = 0.01\n",
    "min_gama = 1e-10\n",
    "epsilon = 0.001\n",
    "min_gama_sum = 1e-4\n",
    "\n",
    "class EM:\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.d = d = len(data[0])\n",
    "        self.m = m = len(data)\n",
    "        self.gama = np.empty((m, k))  # also known as r_ic\n",
    "        self.cluster_means = np.empty((k, d))\n",
    "        self.cluster_std = np.empty(k)\n",
    "        self.cluster_p = np.empty(k)\n",
    "        # keep old to compare for convergence test\n",
    "        self.old_cluster_means = np.empty((k, d))\n",
    "        self.old_cluster_std = np.empty(k)\n",
    "        \n",
    "        # allocate buffers for intermediate results\n",
    "        self.buffer_m_d = np.empty((m, d))\n",
    "        self.buffer_k_d = np.empty((k, d))\n",
    "        self.buffer_c = np.empty(k)\n",
    "        self.buffer_c2 = np.empty(k)\n",
    "        self.buffer_d = np.empty(d)\n",
    "        self.buffer_m = np.empty(m)\n",
    "        self.buffer_m_int = np.empty(m, dtype=int)\n",
    "        \n",
    "    def expectation(self):\n",
    "        spherical_gaussian(self.data, self.cluster_means, self.cluster_std,\n",
    "                          self.buffer_m_d, self.buffer_c, out_m_c=self.gama)\n",
    "        # mupltiply by pi\n",
    "        np.multiply(self.gama, self.cluster_p, out=self.gama)\n",
    "        # now normalize gama to have sum=1 for each case\n",
    "        self.gama.sum(axis=1, out=self.buffer_m)\n",
    "        ## but first! take care of the cases where all clusters have 0 proba\n",
    "        zero_sum_cases = self.buffer_m==0  # that's a boolean array\n",
    "        self.buffer_c.fill(1/(self.k+0.0))\n",
    "        self.gama[zero_sum_cases] = self.buffer_c\n",
    "        self.buffer_m[zero_sum_cases] = 1  # no need to normalize those\n",
    "        np.divide(self.gama, self.buffer_m[None].T, out=self.gama)\n",
    "        \n",
    "    def maximization(self):\n",
    "        # sum by batches to avoid arithmetic errors\n",
    "        batch_sum_axis0(self.gama, self.buffer_c2, out_k=self.buffer_c)\n",
    "        self.buffer_c[self.buffer_c==0] = min_gama_sum\n",
    "        self.gama.T.dot(self.data, out=self.cluster_means)\n",
    "        np.divide(self.cluster_means, self.buffer_c[None].T, out=self.cluster_means)\n",
    "        \n",
    "        np.divide(self.buffer_c, self.m, out=self.cluster_p)\n",
    "        assert np.abs(self.cluster_p.sum() - 1.0) < epsilon, \"sum of pi is != 1.0: %r\" % self.cluster_p.sum()\n",
    "        for c in xrange(self.k):\n",
    "            cov = np.zeros(self.d)\n",
    "            np.subtract(self.data, self.cluster_means[c], out=self.buffer_m_d)\n",
    "            np.square(self.buffer_m_d, out=self.buffer_m_d)\n",
    "            np.multiply(self.buffer_m_d, self.gama.T[c][None].T, out=self.buffer_m_d)\n",
    "            self.buffer_m_d.sum(axis=1, out=self.buffer_m_d.T[0])\n",
    "            np.divide(self.buffer_m_d.T[0], self.buffer_c[c], out=self.buffer_m_d.T[0])\n",
    "            self.cluster_std[c] = max(np.sqrt(self.buffer_m_d.T[0].sum()), min_con)  \n",
    "            \n",
    "    def init_clusters(self):\n",
    "        std = np.std(self.data, axis=0)\n",
    "        mean = np.mean(self.data, axis=0)\n",
    "        min_case = self.data.min(axis=0)\n",
    "        max_case = self.data.max(axis=0)\n",
    "        for d in xrange(self.d):\n",
    "            bound = min(0.2*self.k*std[d], 2.5*std[d])\n",
    "            lower_bound = -bound\n",
    "            upper_bound = bound\n",
    "            if lower_bound+mean[d] < min_case[d]:\n",
    "                lower_bound = min_case[d]-mean[d]\n",
    "            if upper_bound+mean[d] > max_case[d]:\n",
    "                upper_bound = max_case[d]-mean[d]\n",
    "            self.cluster_means.T[d] = np.linspace(lower_bound, upper_bound, num=self.k)\n",
    "        np.add(self.cluster_means, mean, out=self.cluster_means)\n",
    "        self.cluster_std[:] = 1\n",
    "        self.cluster_p[:] = 1/(self.k+0.0)\n",
    "    \n",
    "    def converged(self):\n",
    "        np.subtract(self.cluster_means, self.old_cluster_means, out=self.buffer_k_d)\n",
    "        np.abs(self.buffer_k_d, out=self.buffer_k_d)\n",
    "        np.subtract(self.cluster_std, self.old_cluster_std, out=self.buffer_c)\n",
    "        np.abs(self.buffer_c, out=self.buffer_c)\n",
    "        if self.buffer_k_d.mean() > self.d/np.sqrt(self.k):\n",
    "            return False\n",
    "        if self.buffer_c.mean() > self.d/np.sqrt(self.k):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def em(self, repetations=3, logger=None):\n",
    "        self.init_clusters()\n",
    "        self.expectation()\n",
    "        if logger is not None: logger(self.cluster_means, self.cluster_std, self.cluster_p, self.gama, 0)\n",
    "        for repet in xrange(repetations):\n",
    "            # swap buffers\n",
    "            temp = self.cluster_means\n",
    "            self.cluster_means = self.old_cluster_means\n",
    "            self.old_cluster_means = temp\n",
    "            temp = self.cluster_std\n",
    "            self.cluster_std = self.old_cluster_std\n",
    "            self.old_cluster_std = temp\n",
    "            \n",
    "            self.maximization()\n",
    "            self.expectation()\n",
    "            if logger is not None: logger(self.cluster_means, self.cluster_std, self.cluster_p, self.gama, repet+1)\n",
    "            if self.converged(): break\n",
    "                \n",
    "    def segment(self, out):\n",
    "        data = self.data\n",
    "        np.argmax(self.gama, axis=1, out=self.buffer_m_int)\n",
    "        max_like = self.buffer_m_int\n",
    "        for i in xrange(len(data)):\n",
    "            out[i] = self.cluster_means[max_like[i]]\n",
    "\n",
    "    def error(self, segmented):\n",
    "        return reconstruction_error(self.data, segmented, buffer_m_d=self.buffer_m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement ImageLogger to log the results of the EM algorithm on the image\n",
    "This class logs and visualizes the intermediate and final results of the EM algorithm\n",
    "over an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_image(segmented, size):\n",
    "    segmented = segmented.reshape((size[0], size[1], 3))\n",
    "    segmented = segmented.astype(np.uint8)\n",
    "    return Image.fromarray(segmented)\n",
    "\n",
    "def log_form_mean(mean, small=False):\n",
    "    return str(np.round(mean, 0).astype(int)) if small else str(np.round(mean, 1))\n",
    "\n",
    "class ImageLogger:\n",
    "    def __init__(self, em, size, display_image=True, display_error=True,  display_clusters=True):\n",
    "        self.em = em\n",
    "        self.results = pd.DataFrame(columns=['Clusters', 'Iteration', 'Error'])\n",
    "        self.size = size\n",
    "        self.out = np.empty((len(em.data), 3))\n",
    "        self.display_image = display_image\n",
    "        self.display_error = display_error\n",
    "        self.display_clusters = display_clusters\n",
    "        self.display = display_image or display_error or display_clusters\n",
    "    \n",
    "    def __call__(self, means, std, p, _, repet):\n",
    "        self.em.segment(self.out)\n",
    "        error = self.em.error(self.out)\n",
    "        self.results.loc[len(self.results)] = [self.em.k, repet, error]\n",
    "        if not self.display: return\n",
    "        head = 'Iteration '+str(repet) if repet > 0 else 'Initial assignment'\n",
    "        output = ('<div style=\"margin-top:1rem\">'\n",
    "            +'<div style=\"margin-bottom:0.7rem;color:#264747;font-size:1.8rem\">'+head+'</div>')\n",
    "        if self.display_clusters:\n",
    "            std = np.round(std, 2)\n",
    "            for c in xrange(len(means)):\n",
    "                pc = str(np.round(p[c]*100, 3))+'%'\n",
    "                mc = log_form_mean(means[c])\n",
    "                mc_small = log_form_mean(means[c], True)\n",
    "                wrap_style = \"display:inline-block;text-align:left;margin-right:1.5rem;margin-bottom:0.5rem;line-height: 1.3;color:darkslategray\"\n",
    "                style = \"background:rgb(\"+str(means[c][0])+\",\"+str(means[c][1])+\",\"+str(means[c][2])+\");display:inline-block;width:7rem;height:2em;border:1px solid darkgray\"\n",
    "                output = output+'<div style=\"'+wrap_style+'\"><div style=\"'+style+'\" title=\"'+mc+'\"></div><br>&nbsp;'+mc_small+'<br> &nbsp;std: '+str(std[c])+\"<br/> &nbsp;p: &nbsp;&nbsp; \"+pc+\"</div>\"\n",
    "        if self.display_error:\n",
    "            output = output+\"<div style='margin-top:0.1rem'><strong>Error: \"+str(error)+\"</strong></div>\"\n",
    "        display(HTML(output+\"</div>\"))\n",
    "        if self.display_image:\n",
    "            display(self.get_image())\n",
    "        \n",
    "    def get_image(self):\n",
    "        return to_image(self.out, self.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "\n",
    "image = Image.open(\"data/traino.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now,  test the algorithm with K=32\n",
    "We will run the algorithm and display the progression of the error and of\n",
    "the progression color clusters for each iteration.\n",
    "\n",
    "Colors correspond to the cluster means.\n",
    "\n",
    "(The resulting image is not displayed here to reduce the size of this \n",
    "file however it will be available at \"results/k-32.png\" upon completion of this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.asarray(image)\n",
    "print 'Original Input Size:', len(data), \"X\", len(data[0])\n",
    "\n",
    "data_flat = data.astype(float).reshape((len(data)*len(data[0]), 3))\n",
    "print 'Flattened Size:', len(data_flat)\n",
    "\n",
    "em = EM(data_flat, 32)\n",
    "logger = ImageLogger(em, (len(data), len(data[0])), display_image=False)\n",
    "em.em(20, logger)\n",
    "\n",
    "display(logger.results)\n",
    "#display(logger.get_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and obtain results for K=2, 4, 8, 16, 24, 32\n",
    "NOTE: Maximum iterations are set to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, errno\n",
    "\n",
    "# make directory for results\n",
    "try: os.makedirs(\"results\")\n",
    "except OSError as e:\n",
    "     if e.errno != errno.EEXIST: raise\n",
    "\n",
    "results = pd.DataFrame(columns=['Clusters', 'Iterations', 'Error'])\n",
    "KS_TO_TEST = [2, 4, 8, 16, 24, 32]\n",
    "IMAGE_COMPARISSON_HEIGHT = 1050\n",
    "image_comparisson_width = int(np.ceil((float(IMAGE_COMPARISSON_HEIGHT) / ((len(KS_TO_TEST)+1) // 2)) * 2 * (float(image.width) / image.height)))\n",
    "image_comparisson = Image.new(\"RGB\", (image_comparisson_width, IMAGE_COMPARISSON_HEIGHT))\n",
    "\n",
    "y = 0\n",
    "for i, k in enumerate(KS_TO_TEST):\n",
    "    em = EM(data_flat, k)\n",
    "    logger = ImageLogger(em, (len(data), len(data[0])),\n",
    "         display_image=False, display_clusters=False, display_error=False)\n",
    "    em.em(20, logger)\n",
    "    logger.results.to_csv(\"results/k-\"+str(k)+\".csv\",sep = ',')\n",
    "    image_k = logger.get_image()\n",
    "    image_k.save(\"results/k-\"+str(k)+\".png\")\n",
    "    logger.results.rename(columns={'Iteration': 'Iterations'}, inplace=True)\n",
    "    last_row = logger.results.iloc[-1]\n",
    "    results.loc[len(results)] = last_row\n",
    "    image_k.thumbnail((image_comparisson_width//2, IMAGE_COMPARISSON_HEIGHT//(len(KS_TO_TEST) // 2)), Image.ANTIALIAS)\n",
    "    w, h = image_k.size\n",
    "    x = 0 if i%2==0 else w\n",
    "    image_comparisson.paste(image_k, (x, y, x+w, y+h))\n",
    "    if i%2==1:\n",
    "        y = y+h\n",
    "    print \"k =\", k, \"done\"\n",
    "    \n",
    "\n",
    "results.to_csv(\"results/all-k.csv\",sep = ',')\n",
    "image_comparisson.save(\"results/all-k.png\")\n",
    "display(results)\n",
    "display(image_comparisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(0, (8, 6))\n",
    "plt.plot(results['Clusters'], results['Error'])\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Reconstruction error for different k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known logical imlementation errors\n",
    "The algorithms sometimes gives higher error on iterations that happen after it has converged.\n",
    "The magnitude of the difference is very small to be noticed by naked eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits\n",
    "The algorithm, on the application of image segmentation behaves well for values of k at most around 180.\n",
    "For k=256, for example, it merges most of the clusters into a single cluster with the same mean and std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible improvements\n",
    "The implemetnation can be tweaked to allow the application of the algorithm\n",
    "over an SRS of the total dataset which will dramatically improve performance.\n",
    "\n",
    "\n",
    "On the final stage, in should just perform an expectation step over the total dataset\n",
    "to obtain the gamas and then use them to segment the initial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
